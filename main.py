import os
import subprocess
import time
import boto3
import redis
import json
import re
import shutil
import requests
from urllib.parse import urlparse

# Configuration
RENDER_DIR = "/app/render"
OUTPUT_DIR = "/app/render/output"
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")
AWS_REGION = os.getenv("AWS_REGION", "ap-south-1")
REDIS_URL = os.getenv("REDIS_URL")
BACKEND_CALLBACK_URL = os.getenv("BACKEND_CALLBACK_URL")  # New env var

def get_redis_client():
    """Initialize Redis client from REDIS_URL"""
    try:
        return redis.from_url(REDIS_URL, decode_responses=True)
    except Exception as e:
        print(f"[ERROR] Failed to connect to Redis: {e}")
        return None

def download_from_s3(s3_key, local_path):
    """Download Python script from S3"""
    print(f"[INFO] Downloading from S3: {s3_key}")
    s3 = boto3.client("s3", region_name=AWS_REGION)
    try:
        s3.download_file(S3_BUCKET_NAME, s3_key, local_path)
        print("[SUCCESS] Downloaded from S3.")
        return True
    except Exception as e:
        print(f"[ERROR] S3 download failed: {e}")
        return False

def validate_manim_script(script_path):
    """Validate and potentially fix common Manim syntax issues"""
    try:
        with open(script_path, 'r') as f:
            content = f.read()

        # Fix common syntax issues
        fixes = [
            (r'\.set_fill\(([^,]+),\s*opacity=([^)]+)\)', r'.set_fill(\1).set_opacity(\2)'),
            (r'Text\(([^,]+),\s*font_size=([^)]+)\)', r'Text(\1).scale(\2/48)'),
        ]

        original_content = content
        for pattern, replacement in fixes:
            content = re.sub(pattern, replacement, content)

        if content != original_content:
            with open(script_path, 'w') as f:
                f.write(content)
            print(f"[INFO] Fixed syntax issues in {script_path}")

        return True
    except Exception as e:
        print(f"[ERROR] Script validation failed: {e}")
        return False

def render_manim_file(file_path):
    """Render Manim file to video"""
    print(f"[INFO] Rendering {file_path}...")

    if not validate_manim_script(file_path):
        return False

    try:
        subprocess.run([
            "manim",
            "-ql",
            file_path,
            "AutoGeneratedScene"
        ], check=True)
        print("[SUCCESS] Render complete.")
        return True
    except subprocess.CalledProcessError as e:
        print(f"[ERROR] Rendering failed: {e}")
        return False

def find_latest_video(file_basename):
    """Find the rendered video file"""
    media_root = "/app/media/videos"
    for root, dirs, files in os.walk(media_root):
        for file in files:
            if file.endswith(".mp4") and "AutoGeneratedScene" in file and file_basename in root:
                return os.path.join(root, file)
    return None

def upload_to_s3(file_path, key):
    """Upload file to S3"""
    print(f"[INFO] Uploading to S3: {key}")
    s3 = boto3.client("s3", region_name=AWS_REGION)
    try:
        s3.upload_file(file_path, S3_BUCKET_NAME, key)
        print("[SUCCESS] Uploaded to S3.")
        return True
    except Exception as e:
        print(f"[ERROR] S3 upload failed: {e}")
        return False

def update_job_status(redis_client, job_id, status, video_url=None):
    """Update job status in Redis"""
    try:
        redis_client.hset(f"job:{job_id}", "status", status)
        redis_client.hset(f"job:{job_id}", "updatedAt", time.time())
        if video_url:
            redis_client.hset(f"job:{job_id}", "videoUrl", video_url)
        print(f"[INFO] Updated job {job_id} status to {status}")
        return True
    except Exception as e:
        print(f"[ERROR] Failed to update job status: {e}")
        return False

def notify_backend(job_id, video_url):
    """Notify backend that video is ready"""
    if not BACKEND_CALLBACK_URL:
        print("[WARN] BACKEND_CALLBACK_URL not set, skipping notification.")
        return False

    payload = {
       "promptId": job_id,      
       "url": video_url 
    }

    try:
        response = requests.post(BACKEND_CALLBACK_URL, json=payload)
        if response.status_code == 200:
            print(f"[INFO] Successfully notified backend for job {job_id}")
            return True
        else:
            print(f"[ERROR] Backend responded with status {response.status_code}: {response.text}")
            return False
    except Exception as e:
        print(f"[ERROR] Failed to notify backend: {e}")
        return False

def process_job(job_data, redis_client):
    """Process a single render job"""
    job_id = job_data['jobId']
    s3_key = job_data['s3Key']

    try:
        print(f"[INFO] Processing job: {job_id}")
        update_job_status(redis_client, job_id, 'processing')

        script_path = os.path.join(RENDER_DIR, f"{job_id}.py")
        if not download_from_s3(s3_key, script_path):
            update_job_status(redis_client, job_id, 'failed')
            return False

        if not render_manim_file(script_path):
            update_job_status(redis_client, job_id, 'failed')
            return False

        output_video = find_latest_video(job_id)
        if not output_video:
            print(f"[ERROR] No video found for job {job_id}")
            update_job_status(redis_client, job_id, 'failed')
            return False

        output_name = f"{job_id}.mp4"
        local_output_path = os.path.join(OUTPUT_DIR, output_name)
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        shutil.copy2(output_video, local_output_path)
        print(f"[INFO] Video saved at: {local_output_path}")

        video_s3_key = f"videos/{output_name}"
        if not upload_to_s3(local_output_path, video_s3_key):
            update_job_status(redis_client, job_id, 'failed')
            return False

        video_url = f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{video_s3_key}"
        update_job_status(redis_client, job_id, 'completed', video_url)

        notify_backend(job_id, video_url)

        try:
            os.remove(script_path)
            os.remove(local_output_path)
            media_job_dir = f"/app/media/videos/{job_id}"
            if os.path.exists(media_job_dir):
                shutil.rmtree(media_job_dir)
        except Exception as cleanup_error:
            print(f"[WARN] Cleanup failed: {cleanup_error}")

        print(f"[SUCCESS] Job {job_id} completed successfully")
        return True

    except Exception as e:
        print(f"[ERROR] Job processing failed: {e}")
        update_job_status(redis_client, job_id, 'failed')
        return False

def worker_loop():
    """Main worker loop"""
    redis_client = get_redis_client()
    if not redis_client:
        print("[ERROR] Cannot connect to Redis. Exiting.")
        return

    print("[INFO] Worker started, waiting for jobs...")

    while True:
        try:
            job = redis_client.brpop('renderQueue', timeout=10)
            if job:
                job_data = json.loads(job[1])
                process_job(job_data, redis_client)
            else:
                print("[INFO] No jobs in queue, waiting...")

        except KeyboardInterrupt:
            print("[INFO] Worker stopped by user")
            break
        except Exception as e:
            print(f"[ERROR] Worker error: {e}")
            time.sleep(5)

def main():
    if not S3_BUCKET_NAME:
        print("[ERROR] S3_BUCKET_NAME environment variable is required")
        return

    if not REDIS_URL:
        print("[ERROR] REDIS_URL environment variable is required")
        return

    os.makedirs(RENDER_DIR, exist_ok=True)
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    worker_loop()

if __name__ == "__main__":
    print("[BOOT] Manim Worker started.")
    main()
